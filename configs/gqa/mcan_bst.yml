# Network
MODEL_USE: mcan
LAYER: 6
HIDDEN_SIZE: 512
FF_SIZE: 2048
MULTI_HEAD: 8
DROPOUT_R: 0.1
FLAT_MLP_SIZE: 512
FLAT_GLIMPSES: 1
FLAT_OUT_SIZE: 1024
USE_BBOX_FEAT: True
WIDTH_SET: [1/4, 1/2, 3/4, 1]
DEPTH_SET: [1/6, 1/3, 2/3, 1]

# Execution
BATCH_SIZE: 64
LR_BASE: 0.0001
LR_DECAY_R: 0.2
LR_DECAY_LIST: [8, 10]
WARMUP_EPOCH: 2
MAX_EPOCH: 11
GRAD_NORM_CLIP: -1
GRAD_ACCU_STEPS: 1
LOSS_FUNC: kld
LOSS_REDUCTION: sum
OPT: Adam
OPT_PARAMS: {betas: '(0.9, 0.98)', eps: '1e-9'}
TEA_WEIGHT: './ckpts/teacher_model_weights/gqa_teacher_epoch11.pkl'  # train + val -> test-dev
SAMPLED_K: 5
